name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  AWS_REGION: us-east-1
  NODE_ENV: production

jobs:
  # Code Quality Checks
  quality:
    name: Code Quality
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: |
            package-lock.json
            frontend/package-lock.json
            backend/package-lock.json

      - name: Install dependencies
        run: |
          cd frontend && npm ci
          cd ../backend && npm ci

      - name: Lint frontend
        run: |
          cd frontend
          npm run lint || echo "No lint script defined"

      - name: Lint backend
        run: |
          cd backend
          npm run lint || echo "No lint script defined"

      - name: Test frontend
        run: |
          cd frontend
          npm test -- --coverage --watchAll=false || echo "Tests failed or not defined"

      - name: Test backend
        run: |
          cd backend
          npm test || echo "Tests failed or not defined"

  # Build Application
  build:
    name: Build Application
    runs-on: ubuntu-latest
    needs: quality
    outputs:
      frontend-hash: ${{ steps.hash.outputs.frontend }}
      backend-hash: ${{ steps.hash.outputs.backend }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'
          cache-dependency-path: |
            package-lock.json
            frontend/package-lock.json
            backend/package-lock.json

      - name: Build frontend
        run: |
          cd frontend
          npm ci
          npm run build
          cd ..

      - name: Build backend
        run: |
          cd backend
          npm ci
          npm run build || echo "No build script defined"
          cd ..

      - name: Generate build hashes
        id: hash
        run: |
          echo "frontend=$(find frontend/build -type f -exec md5sum {} \; | sort | md5sum | cut -d' ' -f1)" >> $GITHUB_OUTPUT
          echo "backend=$(find backend -name "*.js" -type f -exec md5sum {} \; | sort | md5sum | cut -d' ' -f1)" >> $GITHUB_OUTPUT

      - name: Upload frontend build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: frontend-build-${{ github.sha }}
          path: frontend/build/

      - name: Upload backend build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: backend-build-${{ github.sha }}
          path: backend/

  # Deploy to Development
  deploy-dev:
    name: Deploy to Development
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/develop' && github.event_name == 'push'
    environment: development
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.6.6"

      - name: Check AWS Limits
        run: |
          echo "Checking AWS EIP limits..."
          EIP_COUNT=$(aws ec2 describe-addresses --query 'Addresses | length' --output text)
          echo "Current EIP count: $EIP_COUNT"
          if [ "$EIP_COUNT" -ge 5 ]; then
            echo "⚠️ WARNING: Approaching EIP limit ($EIP_COUNT/5)"
            echo "Consider requesting a limit increase or cleaning up unused EIPs"
          fi

      - name: Validate deployment requirements
        run: |
          echo "=== Validating Production Deployment Requirements ==="

          # Check DB password
          if [ -z "${{ secrets.DB_PASSWORD }}" ]; then
            echo "❌ DB_PASSWORD secret is not set in GitHub repository"
            echo "Please add DB_PASSWORD to your repository secrets:"
            echo "1. Go to your repository settings"
            echo "2. Navigate to Secrets and variables > Actions"
            echo "3. Add a new secret named 'DB_PASSWORD'"
            echo "4. Set a secure password (8-41 characters, letters, numbers, and @#\$%^&+=*! symbols only)"
            exit 1
          fi

          # Validate DB password format
          if [[ "${{ secrets.DB_PASSWORD }}" =~ ^[A-Za-z0-9@#\$%\^\&\+\=\*\!]{8,41}$ ]]; then
            echo "✅ DB password format is valid"
          else
            echo "❌ DB password must be 8-41 characters and contain only letters, numbers, and @#\$%^&+=*! symbols"
            exit 1
          fi

          # Check AWS credentials
          if [ -z "${{ secrets.AWS_ACCESS_KEY_ID }}" ] || [ -z "${{ secrets.AWS_SECRET_ACCESS_KEY }}" ]; then
            echo "❌ AWS credentials are not properly configured"
            echo "Please add AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY to your repository secrets"
            exit 1
          fi

          # Validate AWS region
          if [ -z "${{ env.AWS_REGION }}" ]; then
            echo "❌ AWS_REGION environment variable is not set"
            exit 1
          fi

          echo "✅ All production deployment requirements validated"


      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: frontend-build-${{ github.sha }}
          path: frontend/build/
        continue-on-error: true

      - name: Download backend artifacts
        uses: actions/download-artifact@v4
        with:
          name: backend-build-${{ github.sha }}
          path: backend/
        continue-on-error: true

      - name: Create deployment variables file
        run: |
          cat > terraform/ci-deploy.tfvars << EOF
          environment = "dev"
          db_password = "${{ secrets.DB_PASSWORD }}"
          aws_region = "${{ env.AWS_REGION }}"
          project_name = "jobboard"
          db_username = "jobboard_user"
          instance_type = "t2.micro"
          key_pair_name = "jobboard-key"
          EOF

      - name: Initialize Terraform
        run: |
          cd terraform
          echo "Initializing Terraform..."
          terraform init

      - name: Import existing resources
        run: |
          cd terraform

          # Function to import resource if it exists, create if it doesn't
          import_or_create_resource() {
            local resource_type="$1"
            local resource_name="$2"
            local filter_value="$3"

            echo "Checking for existing $resource_type: $resource_name..."

            if [ "$resource_type" = "vpc" ]; then
              RESOURCE_ID=$(aws ec2 describe-vpcs --filters Name=tag:Name,Values="$filter_value" --query 'Vpcs[0].VpcId' --output text 2>/dev/null || echo "")
            elif [ "$resource_type" = "subnet" ]; then
              # For subnets, also check by CIDR block to avoid conflicts
              SUBNET_CIDR="$4"
              if [ ! -z "$SUBNET_CIDR" ]; then
                RESOURCE_ID=$(aws ec2 describe-subnets --filters Name=cidr-block,Values="$SUBNET_CIDR" --query 'Subnets[0].SubnetId' --output text 2>/dev/null || echo "")
              fi
              # Fallback to tag-based search if CIDR search fails
              if [ -z "$RESOURCE_ID" ] || [ "$RESOURCE_ID" = "None" ]; then
                RESOURCE_ID=$(aws ec2 describe-subnets --filters Name=tag:Name,Values="$filter_value" --query 'Subnets[0].SubnetId' --output text 2>/dev/null || echo "")
              fi
            elif [ "$resource_type" = "security_group" ]; then
              RESOURCE_ID=$(aws ec2 describe-security-groups --filters Name=tag:Name,Values="$filter_value" --query 'SecurityGroups[0].GroupId' --output text 2>/dev/null || echo "")
            elif [ "$resource_type" = "iam_role" ]; then
              RESOURCE_ID=$(aws iam get-role --role-name "$filter_value" --query 'Role.RoleName' --output text 2>/dev/null || echo "")
            elif [ "$resource_type" = "route_table_association" ]; then
              # Special handling for route table associations - get proper subnet and route table IDs by name tags
              SUBNET_NAME="$4"
              ROUTE_TABLE_NAME="$5"

              # Get subnet ID by name tag
              SUBNET_ID=$(aws ec2 describe-subnets --filters Name=tag:Name,Values="$SUBNET_NAME" --query 'Subnets[0].SubnetId' --output text 2>/dev/null || echo "")

              # Get route table ID by name tag
              ROUTE_TABLE_ID=$(aws ec2 describe-route-tables --filters Name=tag:Name,Values="$ROUTE_TABLE_NAME" --query 'RouteTables[0].RouteTableId' --output text 2>/dev/null || echo "")

              if [ ! -z "$SUBNET_ID" ] && [ ! -z "$ROUTE_TABLE_ID" ] && [ "$SUBNET_ID" != "None" ] && [ "$ROUTE_TABLE_ID" != "None" ]; then
                # Verify these are actually valid subnet and route table IDs
                SUBNET_CHECK=$(aws ec2 describe-subnets --subnet-ids "$SUBNET_ID" --query 'Subnets[0].SubnetId' --output text 2>/dev/null || echo "")
                RT_CHECK=$(aws ec2 describe-route-tables --route-table-ids "$ROUTE_TABLE_ID" --query 'RouteTables[0].RouteTableId' --output text 2>/dev/null || echo "")

                if [ ! -z "$SUBNET_CHECK" ] && [ ! -z "$RT_CHECK" ] && [ "$SUBNET_CHECK" != "None" ] && [ "$RT_CHECK" != "None" ]; then
                  RESOURCE_ID="$SUBNET_ID/$ROUTE_TABLE_ID"
                  echo "Found valid subnet $SUBNET_ID and route table $ROUTE_TABLE_ID"
                fi
              fi
            elif [ "$resource_type" = "internet_gateway" ]; then
              # Special handling for internet gateway - check if VPC already has one attached
              VPC_ID="$4"
              IGW_ID=$(aws ec2 describe-internet-gateways --filters Name=attachment.vpc-id,Values="$VPC_ID" --query 'InternetGateways[0].InternetGatewayId' --output text 2>/dev/null || echo "")
              if [ ! -z "$IGW_ID" ] && [ "$IGW_ID" != "None" ] && [ "$IGW_ID" != "" ]; then
                RESOURCE_ID=$IGW_ID
                echo "Found existing internet gateway $IGW_ID attached to VPC $VPC_ID"

                # Check if resource is already managed by Terraform
                if terraform state list | grep -q "^$resource_name$"; then
                  echo "ℹ️ Internet gateway $resource_name is already managed by Terraform"
                else
                  if terraform import -var="db_password=${{ secrets.DB_PASSWORD }}" "$resource_name" "$IGW_ID" 2>/dev/null; then
                    echo "✅ Successfully imported internet gateway"
                  else
                    echo "❌ Failed to import internet gateway"
                  fi
                fi
              else
                echo "ℹ️ No internet gateway found for VPC $VPC_ID - will be created by Terraform"
              fi
            elif [ "$resource_type" = "db_subnet_group" ]; then
              # Check for existing DB subnet group by name
              RESOURCE_ID=$(aws rds describe-db-subnet-groups --subnet-group-name "$filter_value" --query 'DBSubnetGroups[0].DBSubnetGroupName' --output text 2>/dev/null || echo "")
            elif [ "$resource_type" = "log_group" ]; then
              # Check for existing CloudWatch log group by exact name
              RESOURCE_ID=$(aws logs describe-log-groups --log-group-name "$filter_value" --query 'logGroups[0].logGroupName' --output text 2>/dev/null || echo "")
            fi

            if [ ! -z "$RESOURCE_ID" ] && [ "$RESOURCE_ID" != "None" ] && [ "$RESOURCE_ID" != "" ]; then
              echo "Found existing $resource_type: $RESOURCE_ID"
              echo "Attempting to import $resource_name with ID $RESOURCE_ID"

              # Check if resource is already managed by Terraform
              if terraform state list | grep -q "^$resource_name$"; then
                echo "ℹ️ Resource $resource_name is already managed by Terraform"
              else
                echo "Attempting to import $resource_name with ID $RESOURCE_ID..."
                if terraform import -var="db_password=${{ secrets.DB_PASSWORD }}" "$resource_name" "$RESOURCE_ID"; then
                  echo "✅ Successfully imported $resource_type: $RESOURCE_ID"
                else
                  echo "⚠️ Import failed for $resource_name - resource may already be imported or ID may be incorrect"
                  echo "   Resource ID used: $RESOURCE_ID"
                  # Continue anyway - Terraform will handle creation if import fails
                fi
              fi
            else
              echo "No existing $resource_type found with the specified criteria"
            fi
          }

          # Import VPC first
          import_or_create_resource "vpc" "aws_vpc.main" "jobboard-vpc"

          # Get VPC ID for internet gateway import
          VPC_ID=$(aws ec2 describe-vpcs --filters Name=tag:Name,Values=jobboard-vpc --query 'Vpcs[0].VpcId' --output text 2>/dev/null || echo "")

          # Import internet gateway (check if VPC already has one attached)
          import_or_create_resource "internet_gateway" "aws_internet_gateway.main" "jobboard-igw" "$VPC_ID"

          # Import subnets with CIDR blocks to avoid conflicts
          import_or_create_resource "subnet" "aws_subnet.public[0]" "jobboard-public-subnet-1" "10.0.1.0/24"
          import_or_create_resource "subnet" "aws_subnet.public[1]" "jobboard-public-subnet-2" "10.0.2.0/24"
          import_or_create_resource "subnet" "aws_subnet.private[0]" "jobboard-private-subnet-1" "10.0.3.0/24"
          import_or_create_resource "subnet" "aws_subnet.private[1]" "jobboard-private-subnet-2" "10.0.4.0/24"

          # Import security groups
          import_or_create_resource "security_group" "aws_security_group.web" "jobboard-web-sg"
          import_or_create_resource "security_group" "aws_security_group.app" "jobboard-app-sg"
          import_or_create_resource "security_group" "aws_security_group.db" "jobboard-db-sg"

          # Import DB subnet group
          import_or_create_resource "db_subnet_group" "aws_db_subnet_group.main" "jobboard-db-subnet-group"

          # Import CloudWatch log group
          import_or_create_resource "log_group" "aws_cloudwatch_log_group.app" "/aws/ec2/${PROJECT_NAME:-jobboard}-app"

          # Import route table associations
          import_or_create_resource "route_table_association" "aws_route_table_association.public[0]" "jobboard-public-subnet-1" "jobboard-public-rt"
          import_or_create_resource "route_table_association" "aws_route_table_association.public[1]" "jobboard-public-subnet-2" "jobboard-public-rt"
          import_or_create_resource "route_table_association" "aws_route_table_association.private[0]" "jobboard-private-subnet-1" "jobboard-private-rt-1"
          import_or_create_resource "route_table_association" "aws_route_table_association.private[1]" "jobboard-private-subnet-2" "jobboard-private-rt-2"

          # Import IAM role
          import_or_create_resource "iam_role" "aws_iam_role.ec2_role" "jobboard-ec2-role"

      - name: Deploy infrastructure
        run: |
          cd terraform

          echo "=== Terraform Deployment Started ==="
          echo "Environment: ${{ github.ref == 'refs/heads/main' && 'production' || 'development' }}"
          echo "Timestamp: $(date)"

          echo "Checking AWS EIP limits..."
          EIP_COUNT=$(aws ec2 describe-addresses --query 'Addresses | length' --output text 2>/dev/null) || EIP_COUNT="0"
          echo "Current EIP count: $EIP_COUNT"

          # Validate EIP_COUNT is a number
          if ! [[ "$EIP_COUNT" =~ ^[0-9]+$ ]]; then
            echo "⚠️ Could not determine EIP count, defaulting to 0"
            EIP_COUNT="0"
          fi

          if [ "$EIP_COUNT" -ge 4 ]; then
            echo "⚠️ WARNING: High EIP usage ($EIP_COUNT/5)"
            echo "Consider cleaning up unused EIPs or requesting a limit increase"
          fi

          echo "Running terraform plan..."
          if ! terraform plan -input=false -no-color -var-file=ci-deploy.tfvars -out=tfplan; then
            echo "❌ Terraform plan failed"
            exit 1
          fi

          echo "Applying terraform configuration..."
          if ! terraform apply -input=false -no-color -auto-approve tfplan; then
            echo "❌ Terraform apply failed"
            terraform show tfplan || echo "Could not show plan"
            exit 1
          fi

          echo "✅ Terraform deployment completed successfully"
          terraform output -json || echo "No outputs to display"

      - name: Cleanup variables file
        run: |
          rm -f terraform/ci-deploy.tfvars

      - name: Build and push Docker images
        run: |
          # Login to AWS ECR (if using)
          # aws ecr get-login-password --region $AWS_REGION | docker login --username AWS --password-stdin $ECR_REPO

          # Build and tag images
          docker build -f docker/Dockerfile.backend -t jobboard-backend:latest ./backend
          docker build -f docker/Dockerfile.frontend -t jobboard-frontend:latest ./frontend

          # Push to registry (if using ECR)
          # docker tag jobboard-backend:latest $ECR_REPO/jobboard-backend:latest
          # docker tag jobboard-frontend:latest $ECR_REPO/jobboard-frontend:latest
          # docker push $ECR_REPO/jobboard-backend:latest
          # docker push $ECR_REPO/jobboard-frontend:latest

      - name: Deploy application
        run: |
          # Deploy using Docker Compose or your deployment method
          echo "Deploying to development environment..."
          # Add your deployment commands here

      - name: Run database migrations
        run: |
          # Run database setup script
          mysql -h ${{ secrets.DB_HOST }} -u ${{ secrets.DB_USER }} -p${{ secrets.DB_PASSWORD }} < scripts/setup-db.sql

      - name: Health check
        run: |
          # Wait for application to be ready
          sleep 60
          # Add health check logic here
          echo "Health check completed"

  # Deploy to Production
  deploy-prod:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: build
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    environment: production
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.6.6"

      - name: Check AWS Limits
        run: |
          echo "Checking AWS EIP limits for production..."
          EIP_COUNT=$(aws ec2 describe-addresses --query 'Addresses | length' --output text)
          echo "Current EIP count: $EIP_COUNT"
          if [ "$EIP_COUNT" -ge 5 ]; then
            echo "⚠️ WARNING: Approaching EIP limit ($EIP_COUNT/5)"
            echo "Consider requesting a limit increase or cleaning up unused EIPs"
          fi

      - name: Validate deployment requirements
        run: |
          echo "=== Validating Deployment Requirements ==="

          # Check DB password
          if [ -z "${{ secrets.DB_PASSWORD }}" ]; then
            echo "❌ DB_PASSWORD secret is not set in GitHub repository"
            echo "Please add DB_PASSWORD to your repository secrets:"
            echo "1. Go to your repository settings"
            echo "2. Navigate to Secrets and variables > Actions"
            echo "3. Add a new secret named 'DB_PASSWORD'"
            echo "4. Set a secure password (8-41 characters, letters, numbers, and @#\$%^&+=*! symbols only)"
            exit 1
          fi

          # Validate DB password format
          if [[ "${{ secrets.DB_PASSWORD }}" =~ ^[A-Za-z0-9@#\$%\^\&\+\=\*\!]{8,41}$ ]]; then
            echo "✅ DB password format is valid"
          else
            echo "❌ DB password must be 8-41 characters and contain only letters, numbers, and @#\$%^&+=*! symbols"
            exit 1
          fi

          # Check AWS credentials
          if [ -z "${{ secrets.AWS_ACCESS_KEY_ID }}" ] || [ -z "${{ secrets.AWS_SECRET_ACCESS_KEY }}" ]; then
            echo "❌ AWS credentials are not properly configured"
            echo "Please add AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY to your repository secrets"
            exit 1
          fi

          # Validate AWS region
          if [ -z "${{ env.AWS_REGION }}" ]; then
            echo "❌ AWS_REGION environment variable is not set"
            exit 1
          fi

          echo "✅ All deployment requirements validated"

      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: frontend-build-${{ github.sha }}
          path: frontend/build/
        continue-on-error: true

      - name: Download backend artifacts
        uses: actions/download-artifact@v4
        with:
          name: backend-build-${{ github.sha }}
          path: backend/
        continue-on-error: true

      - name: Create deployment variables file
        run: |
          cat > terraform/ci-deploy.tfvars << EOF
          environment = "prod"
          db_password = "${{ secrets.DB_PASSWORD }}"
          aws_region = "${{ env.AWS_REGION }}"
          project_name = "jobboard"
          db_username = "jobboard_user"
          instance_type = "t2.micro"
          key_pair_name = "jobboard-key"
          deletion_protection = true
          multi_az = true
          EOF

      - name: Initialize Terraform
        run: |
          cd terraform
          echo "Initializing Terraform for production..."
          terraform init

      - name: Import existing resources
        run: |
          cd terraform

          # Function to import resource if it exists, create if it doesn't
          import_or_create_resource() {
            local resource_type="$1"
            local resource_name="$2"
            local filter_value="$3"

            echo "Checking for existing $resource_type: $resource_name..."
            if [ "$resource_type" = "vpc" ]; then
              RESOURCE_ID=$(aws ec2 describe-vpcs --filters Name=tag:Name,Values="$filter_value" --query 'Vpcs[0].VpcId' --output text 2>/dev/null || echo "")
            elif [ "$resource_type" = "subnet" ]; then
              RESOURCE_ID=$(aws ec2 describe-subnets --filters Name=tag:Name,Values="$filter_value" --query 'Subnets[0].SubnetId' --output text 2>/dev/null || echo "")
            elif [ "$resource_type" = "security_group" ]; then
              RESOURCE_ID=$(aws ec2 describe-security-groups --filters Name=tag:Name,Values="$filter_value" --query 'SecurityGroups[0].GroupId' --output text 2>/dev/null || echo "")
            elif [ "$resource_type" = "iam_role" ]; then
              RESOURCE_ID=$(aws iam get-role --role-name "$filter_value" --query 'Role.RoleName' --output text 2>/dev/null || echo "")
            elif [ "$resource_type" = "internet_gateway" ]; then
              # Special handling for internet gateway - check if VPC already has one attached
              VPC_ID="$4"
              IGW_ID=$(aws ec2 describe-internet-gateways --filters Name=attachment.vpc-id,Values="$VPC_ID" --query 'InternetGateways[0].InternetGatewayId' --output text 2>/dev/null || echo "")
              if [ ! -z "$IGW_ID" ] && [ "$IGW_ID" != "None" ] && [ "$IGW_ID" != "" ]; then
                RESOURCE_ID=$IGW_ID
                echo "Found existing internet gateway $IGW_ID attached to VPC $VPC_ID"

                # Check if resource is already managed by Terraform
                if terraform state list | grep -q "^$resource_name$"; then
                  echo "ℹ️ Internet gateway $resource_name is already managed by Terraform"
                else
                  if terraform import -var="db_password=${{ secrets.DB_PASSWORD }}" "$resource_name" "$IGW_ID" 2>/dev/null; then
                    echo "✅ Successfully imported internet gateway"
                  else
                    echo "❌ Failed to import internet gateway"
                  fi
                fi
              else
                echo "ℹ️ No internet gateway found for VPC $VPC_ID - will be created by Terraform"
              fi
            elif [ "$resource_type" = "db_subnet_group" ]; then
              # Check for existing DB subnet group by name
              RESOURCE_ID=$(aws rds describe-db-subnet-groups --subnet-group-name "$filter_value" --query 'DBSubnetGroups[0].DBSubnetGroupName' --output text 2>/dev/null || echo "")
            elif [ "$resource_type" = "log_group" ]; then
              # Check for existing CloudWatch log group by exact name
              RESOURCE_ID=$(aws logs describe-log-groups --log-group-name "$filter_value" --query 'logGroups[0].logGroupName' --output text 2>/dev/null || echo "")
            elif [ "$resource_type" = "route_table_association" ]; then
              # Special handling for route table associations - get proper subnet and route table IDs by name tags
              SUBNET_NAME="$4"
              ROUTE_TABLE_NAME="$5"

              # Get subnet ID by name tag
              SUBNET_ID=$(aws ec2 describe-subnets --filters Name=tag:Name,Values="$SUBNET_NAME" --query 'Subnets[0].SubnetId' --output text 2>/dev/null || echo "")

              # Get route table ID by name tag
              ROUTE_TABLE_ID=$(aws ec2 describe-route-tables --filters Name=tag:Name,Values="$ROUTE_TABLE_NAME" --query 'RouteTables[0].RouteTableId' --output text 2>/dev/null || echo "")

              if [ ! -z "$SUBNET_ID" ] && [ ! -z "$ROUTE_TABLE_ID" ] && [ "$SUBNET_ID" != "None" ] && [ "$ROUTE_TABLE_ID" != "None" ]; then
                # Verify these are actually valid subnet and route table IDs
                SUBNET_CHECK=$(aws ec2 describe-subnets --subnet-ids "$SUBNET_ID" --query 'Subnets[0].SubnetId' --output text 2>/dev/null || echo "")
                RT_CHECK=$(aws ec2 describe-route-tables --route-table-ids "$ROUTE_TABLE_ID" --query 'RouteTables[0].RouteTableId' --output text 2>/dev/null || echo "")

                if [ ! -z "$SUBNET_CHECK" ] && [ ! -z "$RT_CHECK" ] && [ "$SUBNET_CHECK" != "None" ] && [ "$RT_CHECK" != "None" ]; then
                  RESOURCE_ID="$SUBNET_ID/$ROUTE_TABLE_ID"
                  echo "Found valid subnet $SUBNET_ID and route table $ROUTE_TABLE_ID"
                fi
              fi
            fi

            if [ ! -z "$RESOURCE_ID" ] && [ "$RESOURCE_ID" != "None" ] && [ "$RESOURCE_ID" != "" ]; then
              echo "Found existing $resource_type: $RESOURCE_ID"

              # Check if resource is already managed by Terraform
              if terraform state list | grep -q "^$resource_name$"; then
                echo "ℹ️ Resource $resource_name is already managed by Terraform"
              else
                echo "Attempting to import $resource_name with ID $RESOURCE_ID..."
                if terraform import -var="db_password=${{ secrets.DB_PASSWORD }}" "$resource_name" "$RESOURCE_ID"; then
                  echo "✅ Successfully imported $resource_type: $RESOURCE_ID"
                else
                  echo "⚠️ Import failed for $resource_name - resource may already be imported or ID may be incorrect"
                  echo "   Resource ID used: $RESOURCE_ID"
                  # Continue anyway - Terraform will handle creation if import fails
                fi
              fi
            else
              echo "No existing $resource_type found"
            fi
          }

          # Import VPC first
          import_or_create_resource "vpc" "aws_vpc.main" "jobboard-vpc"

          # Get VPC ID for internet gateway import
          VPC_ID=$(aws ec2 describe-vpcs --filters Name=tag:Name,Values=jobboard-vpc --query 'Vpcs[0].VpcId' --output text 2>/dev/null || echo "")

          # Import internet gateway (check if VPC already has one attached)
          import_or_create_resource "internet_gateway" "aws_internet_gateway.main" "jobboard-igw" "$VPC_ID"

          # Import subnets with CIDR blocks to avoid conflicts
          import_or_create_resource "subnet" "aws_subnet.public[0]" "jobboard-public-subnet-1" "10.0.1.0/24"
          import_or_create_resource "subnet" "aws_subnet.public[1]" "jobboard-public-subnet-2" "10.0.2.0/24"
          import_or_create_resource "subnet" "aws_subnet.private[0]" "jobboard-private-subnet-1" "10.0.3.0/24"
          import_or_create_resource "subnet" "aws_subnet.private[1]" "jobboard-private-subnet-2" "10.0.4.0/24"

          # Import security groups
          import_or_create_resource "security_group" "aws_security_group.web" "jobboard-web-sg"
          import_or_create_resource "security_group" "aws_security_group.app" "jobboard-app-sg"
          import_or_create_resource "security_group" "aws_security_group.db" "jobboard-db-sg"

          # Import DB subnet group
          import_or_create_resource "db_subnet_group" "aws_db_subnet_group.main" "jobboard-db-subnet-group"

          # Import CloudWatch log group
          import_or_create_resource "log_group" "aws_cloudwatch_log_group.app" "/aws/ec2/${PROJECT_NAME:-jobboard}-app"

          # Import DB subnet group
          import_or_create_resource "db_subnet_group" "aws_db_subnet_group.main" "jobboard-db-subnet-group"

          # Import CloudWatch log group
          import_or_create_resource "log_group" "aws_cloudwatch_log_group.app" "/aws/ec2/${PROJECT_NAME:-jobboard}-app"

          # Import route table associations
          import_or_create_resource "route_table_association" "aws_route_table_association.public[0]" "jobboard-public-subnet-1" "jobboard-public-rt"
          import_or_create_resource "route_table_association" "aws_route_table_association.public[1]" "jobboard-public-subnet-2" "jobboard-public-rt"
          import_or_create_resource "route_table_association" "aws_route_table_association.private[0]" "jobboard-private-subnet-1" "jobboard-private-rt-1"
          import_or_create_resource "route_table_association" "aws_route_table_association.private[1]" "jobboard-private-subnet-2" "jobboard-private-rt-2"

          # Import IAM role
          import_or_create_resource "iam_role" "aws_iam_role.ec2_role" "jobboard-ec2-role"

      - name: Deploy infrastructure
        run: |
          cd terraform

          echo "=== Production Terraform Deployment Started ==="
          echo "Environment: production"
          echo "Timestamp: $(date)"

          echo "Checking AWS EIP limits for production..."
          EIP_COUNT=$(aws ec2 describe-addresses --query 'Addresses | length' --output text 2>/dev/null) || EIP_COUNT="0"
          echo "Current EIP count: $EIP_COUNT"

          # Validate EIP_COUNT is a number
          if ! [[ "$EIP_COUNT" =~ ^[0-9]+$ ]]; then
            echo "⚠️ Could not determine EIP count, defaulting to 0"
            EIP_COUNT="0"
          fi

          if [ "$EIP_COUNT" -ge 4 ]; then
            echo "⚠️ WARNING: High EIP usage ($EIP_COUNT/5)"
            echo "Consider cleaning up unused EIPs or requesting a limit increase"
          fi

          echo "Running terraform plan..."
          if ! terraform plan -input=false -no-color -var-file=ci-deploy.tfvars -out=tfplan; then
            echo "❌ Terraform plan failed"
            exit 1
          fi

          echo "Applying terraform configuration..."
          if ! terraform apply -input=false -no-color -auto-approve tfplan; then
            echo "❌ Terraform apply failed"
            terraform show tfplan || echo "Could not show plan"
            exit 1
          fi

          echo "✅ Production terraform deployment completed successfully"
          terraform output -json || echo "No outputs to display"

      - name: Cleanup variables file
        run: |
          rm -f terraform/ci-deploy.tfvars

      - name: Build and push Docker images
        run: |
          # Build production images
          docker build -f docker/Dockerfile.backend -t jobboard-backend:prod ./backend
          docker build -f docker/Dockerfile.frontend -t jobboard-frontend:prod ./frontend

      - name: Deploy application
        run: |
          echo "Deploying to production environment..."
          # Add production deployment commands

      - name: Run database migrations
        run: |
          mysql -h ${{ secrets.DB_HOST }} -u ${{ secrets.DB_USER }} -p${{ secrets.DB_PASSWORD }} < scripts/setup-db.sql

      - name: Health check
        run: |
          sleep 120
          echo "Production health check completed"

      - name: Notify deployment
        run: |
          echo "Production deployment completed successfully"
          # Add notification logic (Slack, email, etc.)

  # Security Scanning
  security:
    name: Security Scan
    runs-on: ubuntu-latest
    needs: build
    if: github.event_name == 'push'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run npm audit
        run: |
          cd frontend && npm audit --audit-level=moderate || echo "Security issues found"
          cd ../backend && npm audit --audit-level=moderate || echo "Security issues found"

      - name: Run Snyk (if configured)
        run: |
          # Add Snyk scanning if you have it set up
          echo "Security scanning completed"

  # Cleanup
  cleanup:
    name: Cleanup Artifacts
    runs-on: ubuntu-latest
    if: always()
    needs: [deploy-dev, deploy-prod]
    steps:
      - name: Delete old artifacts
        run: |
          echo "Cleaning up old build artifacts..."
          # Add cleanup logic for old artifacts